{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn a Reward Function using Maximum Conditional Entropy Inverse Reinforcement Learning\n",
    "\n",
    "MCE IRL only supports tabular environments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cliffworld environment, that we use here is a TabularEnvironment.\n",
    "It's observations consist of the POMDP's observations and the actual state.\n",
    "We later also need VecEnv objects that expose just the internal POMDP-state or just the POMDP-observation as its observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imitation.algorithms.mce_irl import (\n",
    "    MCEIRL,\n",
    "    mce_occupancy_measures,\n",
    "    mce_partition_fh,\n",
    "    TabularPolicy,\n",
    ")\n",
    "import gym\n",
    "import imitation.envs.examples.model_envs\n",
    "\n",
    "from imitation.data import rollout\n",
    "from imitation.envs import resettable_env\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from imitation.rewards import reward_nets\n",
    "\n",
    "\n",
    "env_name = \"imitation/CliffWorld15x6-v0\"\n",
    "env = gym.make(env_name)\n",
    "state_venv = resettable_env.DictExtractWrapper(\n",
    "    DummyVecEnv([lambda: gym.make(env_name)] * 4), \"state\"\n",
    ")\n",
    "obs_venv = resettable_env.DictExtractWrapper(\n",
    "    DummyVecEnv([lambda: gym.make(env_name)] * 4), \"obs\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we derive an expert policy using Bellman backups. We analytically compute the occupancy measures, and also sample some expert trajectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expert stats:  {'n_traj': 280, 'return_min': -21.0, 'return_mean': 18.12142857142857, 'return_std': 8.774124178631212, 'return_max': 26.0, 'len_min': 18, 'len_mean': 18.0, 'len_std': 0.0, 'len_max': 18}\n"
     ]
    }
   ],
   "source": [
    "_, _, pi = mce_partition_fh(env)\n",
    "\n",
    "_, om = mce_occupancy_measures(env, pi=pi)\n",
    "\n",
    "expert = TabularPolicy(\n",
    "    state_space=env.pomdp_state_space,\n",
    "    action_space=env.action_space,\n",
    "    pi=pi,\n",
    "    rng=None,\n",
    ")\n",
    "\n",
    "expert_trajs = rollout.generate_trajectories(\n",
    "    policy=expert,\n",
    "    venv=state_venv,\n",
    "    sample_until=rollout.make_min_timesteps(5000),\n",
    ")\n",
    "\n",
    "print(\"Expert stats: \", rollout.rollout_stats(expert_trajs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we set up the MCE algorithm and train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mce_irl(demos, **kwargs):\n",
    "    reward_net = reward_nets.BasicRewardNet(\n",
    "        env.pomdp_observation_space,\n",
    "        env.action_space,\n",
    "        use_action=False,\n",
    "        use_next_state=False,\n",
    "        use_done=False,\n",
    "        hid_sizes=[],\n",
    "    )\n",
    "\n",
    "    mce_irl = MCEIRL(demos, env, reward_net, linf_eps=1e-3)\n",
    "    mce_irl.train(**kwargs)\n",
    "\n",
    "    imitation_trajs = rollout.generate_trajectories(\n",
    "        policy=mce_irl.policy,\n",
    "        venv=state_venv,\n",
    "        sample_until=rollout.make_min_timesteps(5000),\n",
    "    )\n",
    "    print(\"Imitation stats: \", rollout.rollout_stats(imitation_trajs))\n",
    "\n",
    "    return mce_irl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we train it on the analytically computed occupancy measures. This should give a very precise result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "| grad_norm   | 5.87     |\n",
      "| iteration   | 0        |\n",
      "| linf_delta  | 4.08     |\n",
      "| weight_norm | 0.626    |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| grad_norm   | 3.76     |\n",
      "| iteration   | 100      |\n",
      "| linf_delta  | 3.61     |\n",
      "| weight_norm | 7.35     |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| grad_norm   | 2.22     |\n",
      "| iteration   | 200      |\n",
      "| linf_delta  | 2.18     |\n",
      "| weight_norm | 11.3     |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| grad_norm   | 1.37     |\n",
      "| iteration   | 300      |\n",
      "| linf_delta  | 1.34     |\n",
      "| weight_norm | 13.5     |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| grad_norm   | 0.851    |\n",
      "| iteration   | 400      |\n",
      "| linf_delta  | 0.825    |\n",
      "| weight_norm | 14.9     |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| grad_norm   | 0.558    |\n",
      "| iteration   | 500      |\n",
      "| linf_delta  | 0.538    |\n",
      "| weight_norm | 15.9     |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| grad_norm   | 0.392    |\n",
      "| iteration   | 600      |\n",
      "| linf_delta  | 0.376    |\n",
      "| weight_norm | 16.7     |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| grad_norm   | 0.292    |\n",
      "| iteration   | 700      |\n",
      "| linf_delta  | 0.279    |\n",
      "| weight_norm | 17.4     |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| grad_norm   | 0.227    |\n",
      "| iteration   | 800      |\n",
      "| linf_delta  | 0.216    |\n",
      "| weight_norm | 17.9     |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| grad_norm   | 0.182    |\n",
      "| iteration   | 900      |\n",
      "| linf_delta  | 0.173    |\n",
      "| weight_norm | 18.3     |\n",
      "--------------------------\n",
      "Imitation stats:  {'n_traj': 280, 'return_min': -19.0, 'return_mean': 15.975, 'return_std': 10.623899102629748, 'return_max': 26.0, 'len_min': 18, 'len_mean': 18.0, 'len_std': 0.0, 'len_max': 18}\n"
     ]
    }
   ],
   "source": [
    "mce_irl_from_om = train_mce_irl(om)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we train it on trajectories sampled from the expert. This gives a stochastic approximation to occupancy measure, so performance is a little worse. Using more expert trajectories should improve performance -- try it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "| grad_norm   | 6.41     |\n",
      "| iteration   | 0        |\n",
      "| linf_delta  | 4.7      |\n",
      "| weight_norm | 0.567    |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| grad_norm   | 4.51     |\n",
      "| iteration   | 100      |\n",
      "| linf_delta  | 4.32     |\n",
      "| weight_norm | 8.7      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| grad_norm   | 3.36     |\n",
      "| iteration   | 200      |\n",
      "| linf_delta  | 3.23     |\n",
      "| weight_norm | 14.7     |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| grad_norm   | 2.47     |\n",
      "| iteration   | 300      |\n",
      "| linf_delta  | 2.32     |\n",
      "| weight_norm | 19.7     |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| grad_norm   | 1.97     |\n",
      "| iteration   | 400      |\n",
      "| linf_delta  | 1.8      |\n",
      "| weight_norm | 24.6     |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| grad_norm   | 1.76     |\n",
      "| iteration   | 500      |\n",
      "| linf_delta  | 1.57     |\n",
      "| weight_norm | 29.5     |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| grad_norm   | 1.66     |\n",
      "| iteration   | 600      |\n",
      "| linf_delta  | 1.47     |\n",
      "| weight_norm | 34.7     |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| grad_norm   | 1.61     |\n",
      "| iteration   | 700      |\n",
      "| linf_delta  | 1.42     |\n",
      "| weight_norm | 40       |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| grad_norm   | 1.58     |\n",
      "| iteration   | 800      |\n",
      "| linf_delta  | 1.39     |\n",
      "| weight_norm | 45.5     |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| grad_norm   | 1.56     |\n",
      "| iteration   | 900      |\n",
      "| linf_delta  | 1.37     |\n",
      "| weight_norm | 51.1     |\n",
      "--------------------------\n",
      "Imitation stats:  {'n_traj': 280, 'return_min': -88.0, 'return_mean': 10.625, 'return_std': 17.01109144478558, 'return_max': 26.0, 'len_min': 18, 'len_mean': 18.0, 'len_std': 0.0, 'len_max': 18}\n"
     ]
    }
   ],
   "source": [
    "mce_irl_from_trajs = train_mce_irl(expert_trajs[0:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "439158cd89905785fcc749928062ade7bfccc3f087fab145e5671f895c635937"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
