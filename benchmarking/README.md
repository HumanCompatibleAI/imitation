# Benchmarking imitation

This directory contains sacred configuration files for benchmarking imitation's algorithms. For v0.3.2, these correspond to the hyperparameters used in the paper [imitation: Clean Imitation Learning Implementations](https://www.rocamonde.com/publication/gleave-imitation-2022/).

Configuration files can be loaded either from the CLI or from the Python API. The examples below assume that your current working directory is the root of the `imitation` repository. This is not necessarily the case and you should adjust your paths accordingly.

## CLI

```bash
python -m imitation.scripts.<train_script> <algo> with benchmarking/<config_name>.json
```
`train_script` can be either 1) `train_imitation` with `algo` as `bc` or `dagger` or 2) `train_adversarial`  with `algo` as `gail` or `airl`.

## Python

```python
...
ex.add_config('benchmarking/<config_name>.json')
```

# Tuning Hyperparameters

The hyperparameters of any algorithm in imitation can be tuned using the `tuning.py` script.
The benchmarking hyperparameter configs were generated by tuning the hyperparameters using
the search space defined in the `tuning_config.py` script. The tuning script proceeds in two
phases: 1) The hyperparameters are tuned using the search space provided, and 2) the best
hyperparameter config found in the first phase based on the maximum mean return is
re-evaluated on a separate set of seeds, and the mean and standard deviation of these trials
are reported.

To tune the hyperparameters of an algorithm using the default search space provided:
```bash
python tuning.py with example_{algo} 'parallel_run_config.base_named_configs=["{env}"]'
```

In this command, `example_{algo}` provides the default search space and settings to be used for
the specific algorithm, which is defined in the `tuning_config.py` script and
`'parallel_run_config.base_named_configs=["{env}"]'` sets the environment to tune the algorithm in.
See the documentation of `tuning.py` and `parallel.py` scripts for many other arguments that can be
provided through the command line to change the tuning behavior.
