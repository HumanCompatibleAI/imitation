agent_path,checkpoint_interval,seed,show_config,total_timesteps,algorithm_kwargs.demo_batch_size,algorithm_kwargs.gen_replay_buffer_capacity,algorithm_kwargs.n_disc_updates_per_round,common.env_name,common.log_dir.py/reduce,common.log_format_strs,common.log_format_strs_additional.wandb,common.log_level,common.log_root,common.max_episode_steps,common.num_vec,common.parallel,common.wandb.wandb_kwargs.monitor_gym,common.wandb.wandb_kwargs.project,common.wandb.wandb_kwargs.save_code,common.wandb.wandb_name_prefix,common.wandb.wandb_tag,demonstrations.n_expert_demos,demonstrations.rollout_path,expert.loader_kwargs.env_name,expert.loader_kwargs.organization,expert.policy_type,reward.add_std_alpha,reward.ensemble_size,reward.net_cls.py/type,reward.net_kwargs.normalize_input_layer.py/type,reward.normalize_output_layer.py/type,rl.batch_size,rl.rl_cls.py/type,rl.rl_kwargs.batch_size,rl.rl_kwargs.clip_range,rl.rl_kwargs.ent_coef,rl.rl_kwargs.gae_lambda,rl.rl_kwargs.gamma,rl.rl_kwargs.learning_rate,rl.rl_kwargs.max_grad_norm,rl.rl_kwargs.n_epochs,rl.rl_kwargs.vf_coef,train.n_episodes_eval,train.policy_cls,train.policy_kwargs.activation_fn.py/type,train.policy_kwargs.features_extractor_class.py/type,train.policy_kwargs.features_extractor_kwargs.normalize_class.py/type,train.policy_kwargs.net_arch,algo,env_name,expert_return_summary,imit_return_summary
,0,104,False,10000000.0,512,16384,16,seals/Walker2d-v0,"[{'py/type': 'pathlib.PosixPath'}, {'py/tuple': ['/', 'home', 'taufeeque', 'ray_results', 'example_gail_seals_walker_best_hp_eval', 'inner_c8027_00004_4_seed=104_2022-11-09_06-21-24', 'output', 'gail', 'seals_Walker2d-v0', '20221109_062130_84fd94']}]","['tensorboard', 'stdout', 'wandb']",,20,,,1,True,False,imitation,False,,,,/home/taufeeque/imitation/output/train_experts/2022-10-11T06:27:42-07:00/seals_walker_3/rollouts/final.pkl,seals/Walker2d-v0,HumanCompatibleAI,ppo-huggingface,,,imitation.rewards.reward_nets.BasicRewardNet,imitation.util.networks.RunningNorm,imitation.util.networks.RunningNorm,16384,stable_baselines3.ppo.ppo.PPO,128,0.4,0.0007566389899529574,0.92,0.98,1.943992487657563e-05,0.6,20,0.6167177795726859,50,MlpPolicy,torch.nn.modules.activation.ReLU,imitation.policies.base.NormalizeFeaturesExtractor,imitation.util.networks.RunningNorm,"[{'pi': [64, 64], 'vf': [64, 64]}]",GAIL,seals/Walker2d-v0,2672.96 ± 639.375 (n=104),2720.91 ± 466.367 (n=50)
,0,102,False,10000000.0,512,16384,16,seals/Walker2d-v0,"[{'py/type': 'pathlib.PosixPath'}, {'py/tuple': ['/', 'home', 'taufeeque', 'ray_results', 'example_gail_seals_walker_best_hp_eval', 'inner_c8027_00002_2_seed=102_2022-11-09_06-21-24', 'output', 'gail', 'seals_Walker2d-v0', '20221109_062130_471aeb']}]","['tensorboard', 'stdout', 'wandb']",,20,,,1,True,False,imitation,False,,,,/home/taufeeque/imitation/output/train_experts/2022-10-11T06:27:42-07:00/seals_walker_3/rollouts/final.pkl,seals/Walker2d-v0,HumanCompatibleAI,ppo-huggingface,,,imitation.rewards.reward_nets.BasicRewardNet,imitation.util.networks.RunningNorm,imitation.util.networks.RunningNorm,16384,stable_baselines3.ppo.ppo.PPO,128,0.4,0.0007566389899529574,0.92,0.98,1.943992487657563e-05,0.6,20,0.6167177795726859,50,MlpPolicy,torch.nn.modules.activation.ReLU,imitation.policies.base.NormalizeFeaturesExtractor,imitation.util.networks.RunningNorm,"[{'pi': [64, 64], 'vf': [64, 64]}]",GAIL,seals/Walker2d-v0,2672.96 ± 639.375 (n=104),2600.9 ± 565.618 (n=50)
,0,100,False,10000000.0,512,16384,16,seals/Walker2d-v0,"[{'py/type': 'pathlib.PosixPath'}, {'py/tuple': ['/', 'home', 'taufeeque', 'ray_results', 'example_gail_seals_walker_best_hp_eval', 'inner_c8027_00000_0_seed=100_2022-11-09_06-21-22', 'output', 'gail', 'seals_Walker2d-v0', '20221109_062128_c33939']}]","['tensorboard', 'stdout', 'wandb']",,20,,,1,True,False,imitation,False,,,,/home/taufeeque/imitation/output/train_experts/2022-10-11T06:27:42-07:00/seals_walker_3/rollouts/final.pkl,seals/Walker2d-v0,HumanCompatibleAI,ppo-huggingface,,,imitation.rewards.reward_nets.BasicRewardNet,imitation.util.networks.RunningNorm,imitation.util.networks.RunningNorm,16384,stable_baselines3.ppo.ppo.PPO,128,0.4,0.0007566389899529574,0.92,0.98,1.943992487657563e-05,0.6,20,0.6167177795726859,50,MlpPolicy,torch.nn.modules.activation.ReLU,imitation.policies.base.NormalizeFeaturesExtractor,imitation.util.networks.RunningNorm,"[{'pi': [64, 64], 'vf': [64, 64]}]",GAIL,seals/Walker2d-v0,2672.96 ± 639.375 (n=104),2539.56 ± 651.114 (n=50)
,0,103,False,10000000.0,512,16384,16,seals/Walker2d-v0,"[{'py/type': 'pathlib.PosixPath'}, {'py/tuple': ['/', 'home', 'taufeeque', 'ray_results', 'example_gail_seals_walker_best_hp_eval', 'inner_c8027_00003_3_seed=103_2022-11-09_06-21-24', 'output', 'gail', 'seals_Walker2d-v0', '20221109_062130_1ac751']}]","['tensorboard', 'stdout', 'wandb']",,20,,,1,True,False,imitation,False,,,,/home/taufeeque/imitation/output/train_experts/2022-10-11T06:27:42-07:00/seals_walker_3/rollouts/final.pkl,seals/Walker2d-v0,HumanCompatibleAI,ppo-huggingface,,,imitation.rewards.reward_nets.BasicRewardNet,imitation.util.networks.RunningNorm,imitation.util.networks.RunningNorm,16384,stable_baselines3.ppo.ppo.PPO,128,0.4,0.0007566389899529574,0.92,0.98,1.943992487657563e-05,0.6,20,0.6167177795726859,50,MlpPolicy,torch.nn.modules.activation.ReLU,imitation.policies.base.NormalizeFeaturesExtractor,imitation.util.networks.RunningNorm,"[{'pi': [64, 64], 'vf': [64, 64]}]",GAIL,seals/Walker2d-v0,2672.96 ± 639.375 (n=104),2712.06 ± 608.339 (n=50)
,0,101,False,10000000.0,512,16384,16,seals/Walker2d-v0,"[{'py/type': 'pathlib.PosixPath'}, {'py/tuple': ['/', 'home', 'taufeeque', 'ray_results', 'example_gail_seals_walker_best_hp_eval', 'inner_c8027_00001_1_seed=101_2022-11-09_06-21-24', 'output', 'gail', 'seals_Walker2d-v0', '20221109_062129_262d36']}]","['tensorboard', 'stdout', 'wandb']",,20,,,1,True,False,imitation,False,,,,/home/taufeeque/imitation/output/train_experts/2022-10-11T06:27:42-07:00/seals_walker_3/rollouts/final.pkl,seals/Walker2d-v0,HumanCompatibleAI,ppo-huggingface,,,imitation.rewards.reward_nets.BasicRewardNet,imitation.util.networks.RunningNorm,imitation.util.networks.RunningNorm,16384,stable_baselines3.ppo.ppo.PPO,128,0.4,0.0007566389899529574,0.92,0.98,1.943992487657563e-05,0.6,20,0.6167177795726859,50,MlpPolicy,torch.nn.modules.activation.ReLU,imitation.policies.base.NormalizeFeaturesExtractor,imitation.util.networks.RunningNorm,"[{'pi': [64, 64], 'vf': [64, 64]}]",GAIL,seals/Walker2d-v0,2672.96 ± 639.375 (n=104),2642.98 ± 454.699 (n=50)
