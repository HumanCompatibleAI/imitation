agent_path,checkpoint_interval,seed,show_config,total_timesteps,algorithm_kwargs.demo_batch_size,algorithm_kwargs.gen_replay_buffer_capacity,algorithm_kwargs.n_disc_updates_per_round,common.env_name,common.log_dir.py/reduce,common.log_format_strs,common.log_format_strs_additional.wandb,common.log_level,common.log_root,common.max_episode_steps,common.num_vec,common.parallel,common.wandb.wandb_kwargs.monitor_gym,common.wandb.wandb_kwargs.project,common.wandb.wandb_kwargs.save_code,common.wandb.wandb_name_prefix,common.wandb.wandb_tag,demonstrations.n_expert_demos,demonstrations.rollout_path,expert.loader_kwargs.env_name,expert.loader_kwargs.organization,expert.policy_type,reward.add_std_alpha,reward.ensemble_size,reward.net_cls.py/type,reward.net_kwargs.normalize_input_layer.py/type,reward.normalize_output_layer.py/type,rl.batch_size,rl.rl_cls.py/type,rl.rl_kwargs.batch_size,rl.rl_kwargs.clip_range,rl.rl_kwargs.ent_coef,rl.rl_kwargs.gae_lambda,rl.rl_kwargs.gamma,rl.rl_kwargs.learning_rate,rl.rl_kwargs.max_grad_norm,rl.rl_kwargs.n_epochs,rl.rl_kwargs.vf_coef,train.n_episodes_eval,train.policy_cls,train.policy_kwargs.activation_fn.py/type,train.policy_kwargs.features_extractor_class.py/type,train.policy_kwargs.features_extractor_kwargs.normalize_class.py/type,train.policy_kwargs.net_arch,algo,env_name,expert_return_summary,imit_return_summary
,0,101,False,10000000.0,128,16384,16,seals/Swimmer-v0,"[{'py/type': 'pathlib.PosixPath'}, {'py/tuple': ['/', 'home', 'taufeeque', 'ray_results', 'example_airl_seals_swimmer_best_hp_eval', 'inner_be60f_00001_1_seed=101_2022-11-09_06-28-20', 'output', 'airl', 'seals_Swimmer-v0', '20221109_062825_03facf']}]","['tensorboard', 'stdout', 'wandb']",,20,,,1,True,False,imitation,False,,,,/home/taufeeque/imitation/output/train_experts/2022-10-11T06:27:42-07:00/seals_swimmer_0/rollouts/final.pkl,seals/Swimmer-v0,HumanCompatibleAI,ppo-huggingface,,,imitation.rewards.reward_nets.BasicShapedRewardNet,imitation.util.networks.RunningNorm,imitation.util.networks.RunningNorm,16384,stable_baselines3.ppo.ppo.PPO,64,0.1,0.006137718463434523,0.95,0.999,0.0013390060486393868,2,5,0.6162112311062333,50,MlpPolicy,torch.nn.modules.activation.ReLU,imitation.policies.base.NormalizeFeaturesExtractor,imitation.util.networks.RunningNorm,"[{'pi': [64, 64], 'vf': [64, 64]}]",AIRL,seals/Swimmer-v0,298.247 ± 7.80207 (n=104),234.52 ± 7.61457 (n=50)
,0,102,False,10000000.0,128,16384,16,seals/Swimmer-v0,"[{'py/type': 'pathlib.PosixPath'}, {'py/tuple': ['/', 'home', 'taufeeque', 'ray_results', 'example_airl_seals_swimmer_best_hp_eval', 'inner_be60f_00002_2_seed=102_2022-11-09_06-28-21', 'output', 'airl', 'seals_Swimmer-v0', '20221109_062833_74ab85']}]","['tensorboard', 'stdout', 'wandb']",,20,,,1,True,False,imitation,False,,,,/home/taufeeque/imitation/output/train_experts/2022-10-11T06:27:42-07:00/seals_swimmer_0/rollouts/final.pkl,seals/Swimmer-v0,HumanCompatibleAI,ppo-huggingface,,,imitation.rewards.reward_nets.BasicShapedRewardNet,imitation.util.networks.RunningNorm,imitation.util.networks.RunningNorm,16384,stable_baselines3.ppo.ppo.PPO,64,0.1,0.006137718463434523,0.95,0.999,0.0013390060486393868,2,5,0.6162112311062333,50,MlpPolicy,torch.nn.modules.activation.ReLU,imitation.policies.base.NormalizeFeaturesExtractor,imitation.util.networks.RunningNorm,"[{'pi': [64, 64], 'vf': [64, 64]}]",AIRL,seals/Swimmer-v0,298.247 ± 7.80207 (n=104),302.529 ± 7.31652 (n=50)
,0,100,False,10000000.0,128,16384,16,seals/Swimmer-v0,"[{'py/type': 'pathlib.PosixPath'}, {'py/tuple': ['/', 'home', 'taufeeque', 'ray_results', 'example_airl_seals_swimmer_best_hp_eval', 'inner_be60f_00000_0_seed=100_2022-11-09_06-28-14', 'output', 'airl', 'seals_Swimmer-v0', '20221109_062824_6fee49']}]","['tensorboard', 'stdout', 'wandb']",,20,,,1,True,False,imitation,False,,,,/home/taufeeque/imitation/output/train_experts/2022-10-11T06:27:42-07:00/seals_swimmer_0/rollouts/final.pkl,seals/Swimmer-v0,HumanCompatibleAI,ppo-huggingface,,,imitation.rewards.reward_nets.BasicShapedRewardNet,imitation.util.networks.RunningNorm,imitation.util.networks.RunningNorm,16384,stable_baselines3.ppo.ppo.PPO,64,0.1,0.006137718463434523,0.95,0.999,0.0013390060486393868,2,5,0.6162112311062333,50,MlpPolicy,torch.nn.modules.activation.ReLU,imitation.policies.base.NormalizeFeaturesExtractor,imitation.util.networks.RunningNorm,"[{'pi': [64, 64], 'vf': [64, 64]}]",AIRL,seals/Swimmer-v0,298.247 ± 7.80207 (n=104),248.793 ± 2.30907 (n=50)
,0,103,False,10000000.0,128,16384,16,seals/Swimmer-v0,"[{'py/type': 'pathlib.PosixPath'}, {'py/tuple': ['/', 'home', 'taufeeque', 'ray_results', 'example_airl_seals_swimmer_best_hp_eval', 'inner_be60f_00003_3_seed=103_2022-11-09_06-28-21', 'output', 'airl', 'seals_Swimmer-v0', '20221109_062833_72d6bf']}]","['tensorboard', 'stdout', 'wandb']",,20,,,1,True,False,imitation,False,,,,/home/taufeeque/imitation/output/train_experts/2022-10-11T06:27:42-07:00/seals_swimmer_0/rollouts/final.pkl,seals/Swimmer-v0,HumanCompatibleAI,ppo-huggingface,,,imitation.rewards.reward_nets.BasicShapedRewardNet,imitation.util.networks.RunningNorm,imitation.util.networks.RunningNorm,16384,stable_baselines3.ppo.ppo.PPO,64,0.1,0.006137718463434523,0.95,0.999,0.0013390060486393868,2,5,0.6162112311062333,50,MlpPolicy,torch.nn.modules.activation.ReLU,imitation.policies.base.NormalizeFeaturesExtractor,imitation.util.networks.RunningNorm,"[{'pi': [64, 64], 'vf': [64, 64]}]",AIRL,seals/Swimmer-v0,298.247 ± 7.80207 (n=104),299.295 ± 4.40014 (n=50)
,0,104,False,10000000.0,128,16384,16,seals/Swimmer-v0,"[{'py/type': 'pathlib.PosixPath'}, {'py/tuple': ['/', 'home', 'taufeeque', 'ray_results', 'example_airl_seals_swimmer_best_hp_eval', 'inner_be60f_00004_4_seed=104_2022-11-09_06-28-21', 'output', 'airl', 'seals_Swimmer-v0', '20221109_062833_1570e5']}]","['tensorboard', 'stdout', 'wandb']",,20,,,1,True,False,imitation,False,,,,/home/taufeeque/imitation/output/train_experts/2022-10-11T06:27:42-07:00/seals_swimmer_0/rollouts/final.pkl,seals/Swimmer-v0,HumanCompatibleAI,ppo-huggingface,,,imitation.rewards.reward_nets.BasicShapedRewardNet,imitation.util.networks.RunningNorm,imitation.util.networks.RunningNorm,16384,stable_baselines3.ppo.ppo.PPO,64,0.1,0.006137718463434523,0.95,0.999,0.0013390060486393868,2,5,0.6162112311062333,50,MlpPolicy,torch.nn.modules.activation.ReLU,imitation.policies.base.NormalizeFeaturesExtractor,imitation.util.networks.RunningNorm,"[{'pi': [64, 64], 'vf': [64, 64]}]",AIRL,seals/Swimmer-v0,298.247 ± 7.80207 (n=104),295.572 ± 9.13404 (n=50)
