# Tuning Hyperparameters
This directory contains scripts for tuning hyperparameters for imitation learning algorithms.
Additional helper scripts allow for running multiple tuning jobs in parallel on a SLURM cluster.

Use `tune.py` to tune hyperparameters for a single algorithm and environment using Optuna.
If you want to specify a custom algorithm and search space, add it to the dict in `hp_search_spaces.py`.

You can tune using multiple workers in parallel by running multiple instances of `tune.py` that all point to the same journal log file (see `tune.py --help` for details).
To easily launch multiple workers on a SLURM cluster and ensure they don't conflict with each other,
use the `tune_on_slurm.py` script.
This script will launch a SLURM job array with the specified number of workers.
If you want to tune all algorithms on all environments on SLURM, use `tune_all_on_slurm.sh`.

# Legacy Tuning Scripts

Note: There are some legacy tuning scripts that can be used like this:

The hyperparameters of any algorithm in imitation can be tuned using `src/imitation/scripts/tuning.py`.
The benchmarking hyperparameter configs were generated by tuning the hyperparameters using
the search space defined in the `scripts/config/tuning.py`.

The tuning script proceeds in two phases:
1. Tune the hyperparameters using the search space provided.
2. Re-evaluate the best hyperparameter config found in the first phase
   based on the maximum mean return on a separate set of seeds.
   Report the mean and standard deviation of these trials.

To use it with the default search space:
```bash
python -m imitation.scripts.tuning with <algo> 'parallel_run_config.base_named_configs=["<env>"]'
```

In this command:
- `<algo>` provides the default search space and settings for the specific algorithm, which is defined in the `scripts/config/tuning.py`
- `<env>` sets the environment to tune the algorithm in. They are defined in the algo-specifc `scripts/config/train_[adversarial|imitation|preference_comparisons|rl].py` files. For the already tuned environments, use the `<algo>_<env>` named configs here.

See the documentation of `scripts/tuning.py` and `scripts/parallel.py` for many other arguments that can be
provided through the command line to change the tuning behavior.
