version: 2.1

orbs:
  codecov: codecov/codecov@1.0.5
  shellcheck: circleci/shellcheck@2.2.4

defaults: &defaults
  docker:
    - image: humancompatibleai/imitation:base
      auth:
        username: $DOCKERHUB_USERNAME
        password: $DOCKERHUB_PASSWORD
  working_directory: /imitation

executors:
  unit-test:
    <<: *defaults
    resource_class: xlarge
    environment:
      # more CPUs visible but we're throttled to 8, which breaks auto-detect
      NUM_CPUS: 8
  lint:
    <<: *defaults
    # darglint is slow enough that we benefit from xlarge even for linting.
    # However, there's little benefit from larger parallelization (I think there's
    # a handful of files with long docstrings causing the bulk of the time).
    resource_class: xlarge
    environment:
      # If you change these, also change ci/code_checks.sh
      SRC_FILES: src/ tests/ experiments/ examples/ docs/conf.py setup.py
      NUM_CPUS: 8
  type:
    <<: *defaults
    resource_class: medium
    environment:
      # If you change these, also change ci/code_checks.sh
      SRC_FILES: src/ tests/ experiments/ examples/ docs/conf.py setup.py
      NUM_CPUS: 2

commands:
  dependencies:
    # You must still manually update the Docker image if any
    # binary (non-Python) dependencies change.
    description: "Check out and update Python dependencies."
    steps:
      - checkout

      # Download and cache dependencies
      - restore_cache:
          keys:
            - v5-dependencies-{{ checksum "setup.py" }}

      - run:
          name: install dependencies
          # Only create venv if it's not been restored from cache
          command: "[[ -d /venv ]] || ./ci/build_and_activate_venv.sh /venv"


      - save_cache:
          paths:
            - /venv
          key: v5-dependencies-{{ checksum "setup.py" }}

      - run:
          name: install imitation
          # Build a wheel then install to avoid copying whole directory (pip issue #2195)
          command: |
            python setup.py sdist bdist_wheel
            pip install --upgrade --force-reinstall --no-deps dist/imitation-*.whl

      - run:
          name: print installed packages
          command: pip freeze --all

jobs:
  lint:
    executor: lint

    steps:
      - dependencies

      - run:
          name: install shellcheck
          command: |
            curl -Lo /tmp/shellcheck.tar.xz https://github.com/koalaman/shellcheck/releases/download/stable/shellcheck-stable.linux.x86_64.tar.xz
            tar -x shellcheck-stable/shellcheck -f /tmp/shellcheck.tar.xz
            mv shellcheck-stable/shellcheck /usr/local/bin/shellcheck
            rm -rf shellcheck-stable
            chmod a+x /usr/local/bin/shellcheck

      - shellcheck/check:
          dir: .
          # Orb invokes shellcheck once per file. shellcheck complains if file
          # includes another file not given on the command line. Ignore this,
          # since they'll just get checked in a separate shellcheck invocation.
          exclude: SC1091

      - run:
          name: flake8
          command: flake8 --version && flake8 -j "${NUM_CPUS}" ${SRC_FILES}

      - run:
          name: black
          command: black --version && black --check --diff ${SRC_FILES}

      - run:
          name: codespell
          command: codespell -I .codespell.skip --skip='*.pyc,tests/testdata/*,*.ipynb,*.csv' ${SRC_FILES}

      - run:
          name: sphinx
          command: pushd docs/ && make clean && make html && popd

  type:
    executor: type
    steps:
      - dependencies

      - run:
          name: pytype
          command: pytype --version && pytype -j "${NUM_CPUS}" ${SRC_FILES[@]}


  unit-test:
    executor: unit-test
    steps:
      - dependencies

      - run:
          name: Memory Monitor
          command: |
            mkdir /tmp/resource-usage
            export FILE=/tmp/resource-usage/memory.txt
            while true; do
              ps -u root eo pid,%cpu,%mem,args,uname --sort=-%mem >> $FILE
              echo "----------" >> $FILE
              sleep 1
            done
          background: true

      # Note: The setup.py checksum in the cache name ensures that we retrain our expert
      # policies, which are cached in the pytest cache, whenever setup.py changes. This
      # is just a rough heuristic to decide when the experts should be retrained but
      # still better than nothing.
      - restore_cache:
          keys:
            - v6-pytest-cache-{{ checksum "setup.py" }}
            # This prefix-matched key restores the most recent pytest cache with any
            # checksum. If that cached policy happens to be still loadable, we avoid
            # retraining. See https://circleci.com/docs/2.0/caching/#restoring-cache
            - v6-pytest-cache-
          paths:
            - .pytest_cache

      - run:
          name: run tests
          command: |
            # Xdummy-entrypoint.py: starts an X server and sets DISPLAY, then runs wrapped command.
            Xdummy-entrypoint.py pytest -n ${NUM_CPUS} --cov=/venv/lib/python3.8/site-packages/imitation \
                   --cov=tests --junitxml=/tmp/test-reports/junit.xml \
                    -vv tests/
            mv .coverage .coverage.imitation
            coverage combine  # rewrite paths from virtualenv to src/

      - codecov/upload

      - save_cache:
          key: v6-pytest-cache-{{ checksum "setup.py" }}
          paths:
            - .pytest_cache

      - store_artifacts:
          path: /tmp/test-reports
          destination: test-reports

      - store_test_results:
          path: /tmp/test-reports
          unit-test:

      - store_artifacts:
          path: /tmp/resource-usage
          destination: resource-usage

workflows:
  version: 2
  test:
    jobs:
      - lint:
          context:
          - docker-hub-creds
      - type:
          context:
          - docker-hub-creds
      - unit-test:
          context:
          - docker-hub-creds
